<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,… | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…" />
<meta name="author" content="VictorGarritano" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Nessa edição, são abordados assuntos como melhorias na avaliação da compositional generalization, bibliotecas de visão computacional baseadas no PyTorch e um simulador físico estado-da-arte." />
<meta property="og:description" content="Nessa edição, são abordados assuntos como melhorias na avaliação da compositional generalization, bibliotecas de visão computacional baseadas no PyTorch e um simulador físico estado-da-arte." />
<link rel="canonical" href="https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html" />
<meta property="og:url" content="https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-16T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-03-16T00:00:00-05:00","dateModified":"2020-03-16T00:00:00-05:00","author":{"@type":"Person","name":"VictorGarritano"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html"},"description":"Nessa edição, são abordados assuntos como melhorias na avaliação da compositional generalization, bibliotecas de visão computacional baseadas no PyTorch e um simulador físico estado-da-arte.","@type":"BlogPosting","url":"https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html","headline":"NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/personal_blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://victorgarritano.github.io/personal_blog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/personal_blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,… | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…" />
<meta name="author" content="VictorGarritano" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Nessa edição, são abordados assuntos como melhorias na avaliação da compositional generalization, bibliotecas de visão computacional baseadas no PyTorch e um simulador físico estado-da-arte." />
<meta property="og:description" content="Nessa edição, são abordados assuntos como melhorias na avaliação da compositional generalization, bibliotecas de visão computacional baseadas no PyTorch e um simulador físico estado-da-arte." />
<link rel="canonical" href="https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html" />
<meta property="og:url" content="https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-16T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-03-16T00:00:00-05:00","dateModified":"2020-03-16T00:00:00-05:00","author":{"@type":"Person","name":"VictorGarritano"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html"},"description":"Nessa edição, são abordados assuntos como melhorias na avaliação da compositional generalization, bibliotecas de visão computacional baseadas no PyTorch e um simulador físico estado-da-arte.","@type":"BlogPosting","url":"https://victorgarritano.github.io/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html","headline":"NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://victorgarritano.github.io/personal_blog/feed.xml" title="fastpages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/personal_blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/personal_blog/about/">About Me</a><a class="page-link" href="/personal_blog/search/">Search</a><a class="page-link" href="/personal_blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-16T00:00:00-05:00" itemprop="datePublished">
        Mar 16, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">VictorGarritano</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      12 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><img src="https://cdn-images-1.medium.com/max/1200/1*9gNslKwKiRaffDt2RSOgoQ.png" alt="" /></p>

<p><br />
Seja muito bem-vindo a sétima edição da NLP Newsletter. Esperamos que você tenha um dia incrível e que você as pessoas que você ama estejam em segurança nessas semanas difíceis. Nós decidimos publicar essa edição na esperança de trazer mais alegria aos nossos leitores. Sendo assim, por favor leia a <em>Newsletter</em> durante o seu tempo livre. Nesse momento, é importante mantermos o foco no que é a verdadeira prioridade - nossa família e amigos. ❤️ 💛 💚</p>

<!-- Welcome to the 7th issue of the NLP Newsletter. I hope you are having a wonderful day and that you and your loved ones are safe in these difficult times. We decided to publish this newsletter to bring some joy to our readers so please read when you have free time. For now, let’s keep focused on the things that are of top priority— our families and friends. ❤️ 💛 💚 -->

<p><br />
<strong><em>Algumas atualizações sobre a NLP Newsletter e a dar.ai</em></strong></p>

<p>Todas as traduções em francês e em chinês das edições anteriores estão agora <a href="https://github.com/dair-ai/nlp_newsletter">disponíveis</a>. Descubra como você pode contribuir com a tradução das edições anteriores (assim como as futuras!) da Newsletter nesse <a href="https://github.com/dair-ai/dair-ai.github.io/issues/11">link</a>.</p>

<ul>
  <li><strong>Nota do tradutor</strong>: As traduções de todas as edições da Newsletter, exceto a 3ª, para português também estão disponíveis!</li>
</ul>

<!-- ***A few updates about the NLP Newsletter and dair.ai***
All French and Chinese translations for the previous issues of the NLP Newsletter are now [available](https://github.com/dair-ai/nlp_newsletter). Find out how you can contribute to the translation of previous and upcoming issues of the NLP Newsletter at this [link](https://github.com/dair-ai/dair-ai.github.io/issues/11). -->

<p><br />
Nós criamos recentemente dois repositórios no Github que contêm <a href="https://github.com/dair-ai/nlp_paper_summaries">resumos de artigos de NLP</a> e <a href="https://github.com/dair-ai/pytorch_notebooks">notebooks utilizando PyTorch</a> para que você possa começar a ter experiência com redes neurais.</p>

<!-- We recently created two GitHub repositories that contain [NLP paper summaries](https://github.com/dair-ai/nlp_paper_summaries) and [PyTorch notebooks](https://github.com/dair-ai/pytorch_notebooks) to get you started with neural networks. -->

<h1 id="pesquisas-e-publicações-">Pesquisas e Publicações 📙</h1>

<p><strong><em>Measuring Compositional Generalization</em></strong></p>

<p><br />
No contexto de Aprendizado de Máquina, <em>compositional generalization</em> se refere a habilidade de representar o conhecimento aprendido com a base de dados e aplicá-lo a novos e diferentes contextos. Até o presente momento, não estava claro como medir essa composicionalidade nas redes neurais. Recentemente, o time de IA da Google <a href="https://ai.googleblog.com/2020/03/measuring-compositional-generalization.html">apresentou</a> um dos maiores <em>benchmarks</em> para <em>compositional generalization</em>, utilizando tarefas como <em>question answering</em> e <em>semantic parsing</em>. A imagem abaixo apresenta um exemplo do modelo proposto utilizando os chamados <em>átomos</em> (unidades utilizadas para se gerar os exemplos) para que sejam produzidos <em>compostos</em> (novas combinações dos átomos). A ideia deste trabalho é construir bases de treino e teste que combinam exemplos que possuem a mesma distribuição pelos diferentes <em>átomos</em> mas com distribuições diferentes sobre os <em>compostos</em>. Os autores argumentam que essa é uma maneira mais confiável de se testar a <em>compositional generalization</em>.</p>

<!-- In the context of machine learning, compositional generalization is the ability to learn to represent meaning and in turn sequences (novel combinations) from what’s learned in the training set. To this date, it is not clear how to properly measure compositionality in neural networks. A Google AI team [proposes](https://ai.googleblog.com/2020/03/measuring-compositional-generalization.html) one of the largest benchmarks for compositional generalization using tasks such as question answering and semantic parsing. The picture below shows an example of the proposed model using atoms (produce, direct, etc.) to produce novel compounds, i.e., combinations of atoms. The idea of this work is to produce a train-test split that contains examples that share similar atoms (building blocks to generate examples) distribution but different compound distribution (the composition of atoms). The authors claim that is a more reliable way to test for compositional generalization. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*lXmUWOY8HJL7YVn1.gif" alt="" /></p>

<p><em>Crédito: Google AI Blog</em></p>

<p><br />
<strong><em>Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping</em></strong></p>

<p><br />
Pesquisadores testaram uma série de <a href="https://arxiv.org/abs/2002.06305">procedimentos de refinamento</a> (<em>fine-tuning</em>) com o objetivo de compreender melhor o efeito das diferentes estratégias de inicialização de pesos e políticas de <em>early stopping</em> no desempenho de modelos de linguagem. Através de exaustivos experimentos de refinamento do BERT, foi constatado que <em>seeds</em> aleatórias distintas produzem resultados bastante discrepantes. Em particular, o estudo reporta que certas inicializações de pesos de fato conferem ao modelo um bom desempenho em diversas tarefas. Todas as bases e testes realizados foram disponibilizadas, para uso de outros pesquisadores interessados em entender as dinâmicas que ocorrem durante o <em>fine-tuning</em> de maneira mais aprofundada.</p>

<!-- Researchers ran a comprehensive [set of fine-tuning trials](https://arxiv.org/abs/2002.06305) to better understand the effect of weight initialization and early stopping in the performance of language models. Through various experiments that involved fine-tuning BERT hundreds of times, it was found that distinct random seeds produce very different results. In particular, the study reports that some weight initialization does perform well across a set of tasks. All the experimental data and trials were publicly released for other researchers that are interested in further understanding different dynamics during fine-tuning. -->

<p><br />
<strong><em>Zoom In: An Introduction to Circuits</em></strong></p>

<p><br />
Pesquisadores da OpenAI publicaram uma <a href="https://distill.pub/2020/circuits/zoom-in/">postagem</a> discutindo o estado atual da tarefa de interpretabilidade de redes neurais, assim como uma nova abordagem para a interpretação das mesmas. Inspirada pela biologia celular, os autores buscaram entender modelos de visão computacional e o que eles aprendem de maneira bastante aprofundada, através da inspeção dos pesos do modelo. Basicamente, o estudo apresentou algumas conclusões, obtidas a partir dos experimentos realizados, as quais eles acreditam que possam ser utilizadas como base para uma melhor interpretação das redes neurais.</p>

<!-- OpenAI researchers published a [piece](https://distill.pub/2020/circuits/zoom-in/) discussing the state of interpretability of neural networks and the proposal of a new approach to interpreting them. Inspired by cellular biology, the authors delve deep into understanding vision models and what they learn by inspecting the weights of neural networks. Essentially, the study presented a few claims along with collected evidence that they believe could pave the way to better interpret neural networks. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*i0c-qpiire6dD4IqJVKlYg.png" alt="" /></p>

<p><br />
<strong><em>NLP Research Highlights — Issue #1</em></strong></p>

<p><br />
Numa nova iniciativa da dar.ai, a <a href="https://medium.com/dair-ai/nlp-newsletter-bertology-primer-fastpages-t5-data-science-education-pytorch-notebooks-slow-8ae5d499e040">NLP Research Highlights</a>, são fornecidas descrições detalhadas de tópicos atuais e bem importantes da pesquisa em NLP. A ideia é que essa iniciativa seja utilizada para acompanhar os avanços da área através de resumos acessíveis desses trabalhos. Na primeira edição trimestral, os tópicos abordados tratam sobre melhorias em modelos de linguagem e em agentes conversacionais para sistemas de reconhecimento de voz. Os resumos são mantidos <a href="https://github.com/dair-ai/nlp_paper_summaries">aqui</a>.</p>

<!-- In a new dair.ai series called [NLP Research Highlights](https://medium.com/dair-ai/nlp-newsletter-bertology-primer-fastpages-t5-data-science-education-pytorch-notebooks-slow-8ae5d499e040), we provide detailed descriptions of current interesting and important NLP research. This will serve as a way to keep track of NLP progress via approachable summaries of these works. In the first quarterly issue, topics range from improving language models to improving conversational agents to state-of-the-art speech recognition systems. These summaries will also be maintained [here](https://github.com/dair-ai/nlp_paper_summaries). -->

<p><br />
<strong><em>Learning to Simulate Complex Physics with Graph Networks</em></strong></p>

<p><br />
Nos últimos meses, as <em>Graph Neural Networks (GNNs)</em> (redes neurais que operam sobre redes) foram um assunto recorrente nas edições da <em>Newsletter</em>, devido a sua efetividade em tarefas não só da área de NLP como também em genômica e materiais. Um <a href="https://arxiv.org/abs/2002.09405">artigo</a> publicado recentemente, propõe um <em>framework</em> geral baseado em <em>GNNs</em> que é capaz de realizar simulações físicas em diferentes cenários, como fluidos e materiais maleáveis. Os autores argumentam que eles obtiveram um desempenho estado-da-arte nesses diferentes contextos e que a abordagem proposta é possivelmente o melhor simulador treinado da atualmente. Os experimentos realizados incluem a simulação de materiais como fluidos viscosos sobre a água e outras interações com objetos rígidos. Também foi testado um modelo pré-treinado em tarefas <em>out-of-distribution</em> e os resultados obtidos foram bastante promissores, evidenciando o potencial de generalização para outros cenários.</p>

<!-- In the past few months, we have been featuring a lot about Graph Neural Networks (GNNs) due to their effectiveness not only in NLP but in other areas such as genomics and materials. In a recent [paper](https://arxiv.org/abs/2002.09405), researchers propose a general framework based on graph networks that is able to learn simulations in different domains such as fluids and deformable materials. The authors claim that they achieve state-of-the-art performance across different domains and that their general-purpose approach is potentially the best-learned physics simulator to date. Experiments include the simulation of materials such as goop over water and other interactions with rigid obstacles. They also tested a pre-trained model on out-of-distribution tasks and found promising results that show the generalization of the framework to larger domains. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*48EolUDJoHpYRCTZxgn_qg.png" alt="" /></p>

<p><a href="https://arxiv.org/pdf/2002.09405.pdf"><em>(Sanchez-Gonzalez et al., 2020)</em></a></p>

<p><br />
<strong><em>Modelos BERT para idiomas específicos</em></strong></p>

<p><br />
O BERT Árabe (AraBERT) está agora disponível na biblioteca de <em>Transformers</em> da Hugging Face. Você pode acessar o modelo <a href="https://huggingface.co/aubmindlab/bert-base-arabert">aqui</a> e o artigo <a href="https://arxiv.org/abs/2003.00104">aqui</a>.</p>

<p><br />
Recentemente, uma versão em japonês do BERT também foi <a href="https://github.com/akirakubo/bert-japanese-aozora">disponibilizada</a>. Uma versão em polonês também está disponível, batizada como <a href="https://github.com/kldarek/polbert">Polbert</a>.</p>

<!-- Arabic BERT (AraBERT) is now available in the Hugging Face Transformer library. You can access the model [here](https://huggingface.co/aubmindlab/bert-base-arabert) and the paper [here](https://arxiv.org/abs/2003.00104). Recently, a Japanese version of BERT was also [released](https://github.com/akirakubo/bert-japanese-aozora). And there is also a Polish version of BERT called [Polbert](https://github.com/kldarek/polbert). -->

<h1 id="criatividade-ética-e-sociedade-">Criatividade, Ética e Sociedade 🌎</h1>

<p><strong><em>Computational predictions of protein structures associated with COVID-19</em></strong></p>

<p><br />
A DeepMind publicou suas <a href="https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19">predições de estruturas</a> das proteínas que se ligam ao vírus causador da COVID-19. As predições foram obtidas diretamente do sistema AlphaFold, embora não tenham sido verificadas experimentalmente. A ideia é que essa publicações encorajem outras contribuições que busquem entender melhor e vírus e suas funções.</p>

<!-- DeepMind releases [computationally-predicted structures](https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19) for proteins linked with the virus related to COVID-19. The predictions are directly obtained from the AlphaFold systems but haven’t been experimentally verified. The idea with this release is to encourage contributions that aim to better understand the virus and how it functions. -->

<p><br />
<strong><em>Court cases that sound like the weirdest fights</em></strong></p>

<p><br />
Janelle Shane compartilhou os <a href="https://aiweirdness.com/post/612669075940900864/court-cases-that-sound-like-the-weirdest-fights">resultados</a> de um divertido experimento onde um modelo do GPT-2 foi refinado para gerar processos judiciais contra objetos inanimados. Foi disponibilizado ao modelo uma lista de processos do governo sobre apreensões de objetivos contrabandeados e artefatos perigosos, e foram geradas acusações como as apresentadas na imagem abaixo.</p>

<!-- Janelle Shane shares the [results](https://aiweirdness.com/post/612669075940900864/court-cases-that-sound-like-the-weirdest-fights) of a fun experiment where a GPT-2 model is fine-tuned to generate cases against inanimate objects. The model was fed a list of cases where the government was seizing contraband or dangerous goods and it generated cases like the ones shown in the picture below. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*E5mHmkm1h4VQJ2Ni.png" alt="" /></p>

<p><a href="https://aiweirdness.com/post/612669075940900864/court-cases-that-sound-like-the-weirdest-fights"><em>fonte</em></a></p>

<p><br />
<strong><em>Toward Human-Centered Design for ML Frameworks</em></strong></p>

<p><br />
A Google AI <a href="https://ai.googleblog.com/2020/03/toward-human-centered-design-for-ml.html">publicou</a> os resultados de uma grande pesquisa com 645 pessoas que utilizaram a versão do TensorFlow para JavaScript. O objetivo era entender quais eram as funcionalidades mais importantes da biblioteca para desenvolvedores fora da área de ML, assim como a sua experiência com as atuais bibliotecas de Aprendizado de Máquina. Uma das conclusões obtidas mostra que a falta de entendimento conceitual de ML dificulta a utilização de bibliotecas específicas para esse grupo de usuários. Os participantes do estudo também reportaram a necessidade de instruções mais acessíveis sobre como aplicar modelos de ML em diferentes problemas e um suporte mais explícito para modificações do usuário.</p>

<!-- Google AI [published](https://ai.googleblog.com/2020/03/toward-human-centered-design-for-ml.html) the results of a large-scale survey of 645 people who used TensorFlow.js. They aimed to find out from non-ML software developers what are the most important features and their overall experience with using current ML frameworks. Findings include that the “lack of conceptual understanding of ML” hinders the use of ML frameworks for this particular set of users. Participants in the study also reported the need for better instructions on how to apply the ML models to different problems and more explicit support for modification. -->

<p><br />
<strong><em>Face and hand tracking in the browser with MediaPipe and TensorFlow.js</em></strong></p>

<p><br />
Este excelente <a href="https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html?linkId=83996111">artigo do TensorFlow</a> apresenta um passo-a-passo para habilitar um sistema de <em>tracking</em> do rosto e das mãos diretamente no navegador utilizando o TensorFlow.js e o MediaPipe.</p>

<!-- This awesome [TensorFlow article](https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html?linkId=83996111) provides a walkthrough of how to enable real-time face and hand tracking on the browser using TensorFlow.js and MediaPipe. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*XsRsB-tSOZo9yWOc.gif" alt="" /></p>

<p><em>Créditos: Blog do TensorFlow</em></p>

<h1 id="ferramentas-e-bases-de-dados-️">Ferramentas e Bases de Dados ⚙️</h1>

<p><strong><em>NLP Paper Summaries</em></strong></p>

<p><br />
Nós criamos recentemente um [repositório]https://github.com/dair-ai/nlp_paper_summaries) contendo uma lista de resumos de artigos de NLP cuidadosamente formulados, para alguns dos mais interessantes e importantes <em>papers</em> da área nos últimos anos. O foco principal da iniciativa é expandir a acessibilidade do público-geral à tópicos e pesquisas de NLP.</p>

<!-- We recently created a [repository](https://github.com/dair-ai/nlp_paper_summaries) containing a list of carefully curated NLP paper summaries for some of the most interesting and important NLP papers in the past few years. The focus is to feature paper summaries and blog posts of important papers to help improve the approachability and accessibility of NLP topics and research. -->

<p><br />
<!-- ***A differentiable computer vision library for PyTorch.*** --></p>

<p><strong><em>Uma biblioteca de visão computacional diferenciável em PyTorch</em></strong></p>

<p><br />
A <a href="https://github.com/kornia/kornia">Kornia</a> é uma biblioteca construída sobre o PyTorch que permite a utilização de uma série de operadores para visão computacional diferenciável utilizando o PyTorch. Algumas das funcionalidades incluem transformações em images, <em>depth estimation</em>, processamento de imagens em baixo-nível, dentre várias outras. O módulo é fortemente inspirado no OpenCV, com a diferença de ser focado em pesquisa, ao invés de aplicações prontas para produção.</p>

<!-- [Kornia](https://github.com/kornia/kornia) is an open-source library built on top of PyTorch that allows researchers to use a set of operators for performing differentiable computer vision using PyTorch. Some capabilities include image transformations, depth estimation, and low-level image processing, to name a few. It is heavily inspired by OpenCV but the difference is that it is meant to be used for research as opposed to building production-ready applications. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*gN_-llcA4_3lIHYE.gif" alt="" /></p>

<p><br />
<strong><em>Introducing DIET: state-of-the-art architecture that outperforms fine-tuning BERT and is 6X faster to train</em></strong></p>

<p><br />
<em>DIET (Dual Intent and Entity Transformer)</em> é uma arquitetura multi-tarefa de <em>natural language understanding (NLU)</em> <a href="https://blog.rasa.com/introducing-dual-intent-and-entity-transformer-diet-state-of-the-art-performance-on-a-lightweight-architecture/">proposta</a> pela Rasa. A <em>framework</em> foca no treinamento multi-tarefa, com o objetivo de melhorar o desempenho nos problemas de classificação de intenções e reconhecimento de entidades nomeadas. Outros benefícios do DIET incluem a flexibilidade de utilização de qualquer <em>embedding</em> pré-treinado, como o BERT e o GloVe. O foco principal, entretanto, é disponibilizar um modelo que ultrapassa o estado-da-arte atual nessas tarefas e que seja mais rápido de treinar (o <em>speedup</em> reportado foi de 6x!). O modelo está disponível na biblioteca <a href="https://rasa.com/docs/rasa/1.8.0/nlu/components/#dietclassifier">rasa</a>.</p>

<!-- DIET (Dual Intent and Entity Transformer) is a natural language understanding (NLU) multitask architecture [proposed](https://blog.rasa.com/introducing-dual-intent-and-entity-transformer-diet-state-of-the-art-performance-on-a-lightweight-architecture/) by Rasa. The framework focuses on multitask training to improve results on both intent classification and entity recognition. Other benefits of DIET include the ability to use any of the current pre-trained embeddings such as BERT and GloVe. However, the focus was to provide a model that improves the current state-of-the-art performance on those tasks and is faster to train (6X speedup reported). The model is available in the [Rasa Open Source python library](https://rasa.com/docs/rasa/1.8.0/nlu/components/#dietclassifier). -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*R_8FOU-CVZabv7hJ.jpg" alt="" /></p>

<p><a href="https://blog.rasa.com/introducing-dual-intent-and-entity-transformer-diet-state-of-the-art-performance-on-a-lightweight-architecture/?utm_source=twitter"><em>framework DIET</em></a></p>

<p><br />
<!-- ***Lost in (language-specific) BERT models?*** -->
<strong><em>Perdido no meio dos modelos BERT?</em></strong></p>

<p><br />
O <a href="https://bertlang.unibocconi.it/">BERT Lang Street</a> é uma plataforma que possui a capacidade de buscar por mais de 30 modelos baseados no BERT, em 18 idiomas e 28 tarefas, totalizando 177 entradas em sua base de dados. Dessa forma, se você quiser descobrir o estado-da-arte para a tarefa de classificação de sentimentos utilizando modelos BERT, basta procurar por <em>“sentiment”</em> na barra de busca (como exemplificado abaixo).</p>

<!-- [BERT Lang Street](https://bertlang.unibocconi.it/) is a neat website that provides the ability to search over 30 BERT-based models with 18 languages and 28 tasks with a total of 177 entries. For instance, if you wanted to find out the state-of-the-art results for sentiment classification using BERT models, you can just search for “sentiment” in the search bar (example shown in the screenshot below). -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*UuVno2eOAzYb_wlSSfukPA.png" alt="" /></p>

<p><br />
<strong><em>Med7</em></strong></p>

<p><br />
O Andrey Kormilitzin disponibilizou o <a href="https://github.com/kormilitzin/med7">Med7</a>, que é um modelo para NLP (em particular Reconhecimento de Entidades Nomeadas (NER)) em relatórios médicos eletrônicos. O modelo é capaz de identificar até 7 categorias de entidades e está disponível para uso com a biblioteca spaCy.</p>

<!-- Andrey Kormilitzin releases [Med7](https://github.com/kormilitzin/med7) which is a model for performing clinical NLP (in particular named entity recognition (NER) tasks) on electronic health records. The model can identify up to seven categories and is available for use with the spaCy library. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*yOMqhvTwYnxB4LYXv2Mgjg.png" alt="" /></p>

<p><br />
<!-- ***An Open Source Library for Quantum Machine Learning*** --></p>

<p><strong><em>Uma biblioteca em código-aberto para Quantum Machine Learning</em></strong></p>

<p><br />
<a href="https://ai.googleblog.com/2020/03/announcing-tensorflow-quantum-open.html">TensorFlow Quantum</a> é uma biblioteca que fornece uma série de funcionalidades para a prototipagem rápida de modelos quânticos de ML, possibilitando a aplicação destes em problemas em áreas como a medicina e materiais.</p>

<!-- [TensorFlow Quantum](https://ai.googleblog.com/2020/03/announcing-tensorflow-quantum-open.html) is an open-source library that provides a toolbox for rapid prototyping of quantum ML research that allows the application of ML models to approach problems ranging from medicine to materials. -->

<p><br />
<strong><em>Fast and Easy Infinitely Wide Networks with Neural Tangents</em></strong></p>

<p><br />
A <em>Neural Tangents</em> é uma biblioteca que permite aos pesquisadores construir e treinar modelos de dimensão infinita e redes neurais utilizando a JAX. Leia a postagem de lançamento <a href="https://ai.googleblog.com/2020/03/fast-and-easy-infinitely-wide-networks.html">aqui</a> e acesse a biblioteca <a href="https://github.com/google/neural-tangents">aqui</a>.</p>

<!-- Neural Tangents is an open-source library that allows researchers to build and train infinite-width models and finite neural networks using JAX. Read the blog post of the release [here](https://ai.googleblog.com/2020/03/fast-and-easy-infinitely-wide-networks.html) and get access to the library [here](https://github.com/google/neural-tangents). -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*CojgKJwB_n_7-j0DJZ0y7g.png" alt="" /></p>

<h1 id="artigos-e-postagens-️">Artigos e Postagens ✍️</h1>

<p><strong><em>From PyTorch to JAX: towards neural net frameworks that purify stateful code</em></strong></p>

<p><br />
Sabrina J. Mielke publicou um <a href="https://sjmielke.com/jax-purify.htm">artigo</a> com um passo-a-passo que ilustra a construção e treinamento de redes neurais utilizado o JAX. A postagem busca comparar o funcionamento interno das redes com o PyTorch e o JAX, o que auxilia num melhor entendimento dos benefícios e diferenças entra as duas bibliotecas.</p>

<!-- Sabrina J. Mielke published an [article](https://sjmielke.com/jax-purify.htm) that provides a walkthrough of how to build and train neural networks using JAX. The article focuses on comparing the inner workings of PyTorch and JAX when building neural networks, which helps to better understand some of the benefits and differences of JAX. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*Nrw4UnmnIZ__elHu.png" alt="" /></p>

<p><a href="https://sjmielke.com/jax-purify.htm"><em>fonte</em></a></p>

<p><br />
<strong><em>Why do we still use 18-year old BLEU?</em></strong></p>

<p><br />
Nesse <a href="https://ehudreiter.com/2020/03/02/why-use-18-year-old-bleu/"><em>blog post</em></a>, Ehud Reiter discorre sobre porquê nós ainda utilizamos técnicas de avaliação antigas como BLUE para mensurar o desempenho de modelos de NLP em tarefas como tradução automática (<em>machine translation</em>). Como um pesquisador da área, ele conta sobre as implicações para técnicas que realizam a avaliação em tarefas de NLP mais recentes.</p>

<!-- In this [blog post](https://ehudreiter.com/2020/03/02/why-use-18-year-old-bleu/), Ehud Reiter talks about why we still use old evaluation techniques like BLUE for evaluating NLP models for tasks like machine translation. As a researcher in the space, he also expresses the implications for techniques that perform the evaluation on more recent tasks. -->

<p><br />
<strong><em>Introducing BART</em></strong></p>

<p><br />
O <a href="https://arxiv.org/abs/1910.13461">BART</a> é um novo modelo proposto pelo Facebook que consiste num <em>denoising autoencoder</em> para o pré-treinamento de modelos <em>sequence-to-sequence</em>, que pode melhorar o desempenho dos mesmos em tarefas como sumarização abstrata. Sam Shleifer disponibilizou um <a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html">resumo interessante</a> do BART e como ele realizou a integração do modelo na biblioteca Transformers da Hugging Face.</p>

<!-- [BART](https://arxiv.org/abs/1910.13461) is a new model proposed by Facebook that involves a denoising autoencoder for pretraining seq2seq models that improve performance on downstream text generation tasks such as abstractive summarization. Sam Shleifer provides a [nice summary](https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html) of BART and how he integrated it into the Hugging Face Transformers repo. -->

<p><br />
<strong><em>A Survey of Long-Term Context in Transformers</em></strong></p>

<p><br />
Madison May escreveu recentemente um <a href="https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context/">compilado</a> bastante interessante descrevendo estratégias para melhorar abordagens baseadas em Transformers, que incluem <em>Sparse Transformers</em>, <em>Adaptive Span Transformers</em>, <em>Transformer-XL</em>, <em>compressive Transformers</em>, <em>Reformer</em>, e <em>routing transformer</em>. Alguns dos modelos já haviam aparecido em <a href="https://medium.com/dair-ai">publicações</a> da dar.ai e na lista de <a href="https://medium.com/dair-ai/nlp-research-highlights-cd522b21b01a">resumos de artigos</a>.</p>

<!-- Madison May recently wrote an interesting [survey](https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context/) describing ways to improve Transformer based approaches, which include Sparse Transformers, Adaptive Span Transformers, Transformer-XL, compressive Transformers, Reformer, and routing transformer. We also touched on some of these topics in the dair.ai [publication](https://medium.com/dair-ai) and in this list of [paper summaries](https://medium.com/dair-ai/nlp-research-highlights-cd522b21b01a). -->

<p><br />
<strong><em>“Mind your language, GPT-2”: how to control style and content in automatic text writing</em></strong></p>

<p><br />
Apesar da fluência impressionante na escrita automática de texto evidenciada no ano passado, continua sendo um desafio controlar atributos como estrutura ou conteúdo em textos gerados por modelos neurais. Numa <a href="https://creatext.ai/blog-posts/controllable-text-generation">postagem recente</a>, Manuel Tonneau discute o progresso atual e as perspectivas na área de geração de texto parametrizável, como o modelo GPT-2 da Hugging Face refinado no arXiv e o T5 da Google, além do CTRL da Salesforce e do PPLM do time de IA da Uber.</p>

<!-- Despite the impressive fluency automatic text writing has exhibited in the past year, it is still challenging to control attributes like structure or content of the machine-written text. In a [recent blog post](https://creatext.ai/blog-posts/controllable-text-generation), Manuel Tonneau discusses the recent progress and the perspectives in the field of controllable text generation, from Hugging Face’s GPT-2 model fine-tuned on arXiv to Google’s T5, with mentions of Salesforce’s CTRL and Uber AI’s PPLM. -->

<h1 id="educação-">Educação 🎓</h1>

<p><br />
<strong><em>Talk: The Future of NLP in Python</em></strong></p>

<p><br />
Em uma de nossas edições anteriores, foi apresentado o <a href="https://thinc.ai/">THiNC</a>, uma biblioteca funcional de <em>Deep Learning</em> focada na compatibilidade com outras já existentes. Essa <a href="https://speakerdeck.com/inesmontani/the-future-of-nlp-in-python-keynote-pycon-colombia-2020?slide=9">apresentação</a>, utilizada pela Ines Montani na PyCon Colombia, introduz a biblioteca mais profundamente.</p>

<!-- In one of our previous newsletters, we featured [THiNC](https://thinc.ai/) which is a functional deep learning library focused on compatibility with other existing libraries. This [set of slides](https://speakerdeck.com/inesmontani/the-future-of-nlp-in-python-keynote-pycon-colombia-2020?slide=9) introduces a bit more of the library which was used in the talk by Ines Montani for PyCon Colombia. -->

<p><br />
<strong><em>Transformers Notebooks</em></strong></p>

<p><br />
A Hugging Face publicou uma coleção de <a href="https://github.com/huggingface/transformers/tree/master/notebooks">notebooks no Colab</a> que auxilia no início da utilização de sua biblioteca Transformers. Alguns notebooks incluem o uso de tokenização, configuração de <em>pipelines</em> de NLP, e o treinamento de modelos de linguagem em bases de dados próprias.</p>

<!-- HuggingFace published a set of [Colab notebooks](https://github.com/huggingface/transformers/tree/master/notebooks) that help to get started with their popular Transformers library. Some notebooks include using tokenization, setting up NLP pipelines, and training a language model on custom data. -->

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*0AYHYUsHbaqV2vqN2zCzLQ.png" alt="" /></p>

<p><br />
<strong><em>TensorFlow 2.0 in 7 hours</em></strong></p>

<p><br />
Confira esse <a href="https://www.freecodecamp.org/news/massive-tensorflow-2-0-free-course/">curso grátis de ~7 horas</a> sobre o TensorFlow 2.0, onde são cobertos tópicos como o básico de redes neurais, NLP com redes neurais recorrentes (RNNs) e uma introdução ao Aprendizado por Reforço.</p>

<!-- Check out this [~7-hour free course](https://www.freecodecamp.org/news/massive-tensorflow-2-0-free-course/) on TensorFlow 2.0 containing topics that range from basic neural networks to NLP with RNNs to an introduction to reinforcement learning. -->

<p><br />
<strong><em>DeepMind: The Podcast</em></strong></p>

<p><br />
A DeepMind liberou todos os episódios (numa <a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZBiUr6_Qf8YTS2Oqy3OGZEj">playlist no YouTube</a>) do seu <em>podcast</em> com cientistas, pesquisadores e engenheiros, onde são discutidos tópicos como *Artificial General Intelligence, neurociência e robótica.</p>

<p><br />
<strong><em>Cursos de Machine Learning and Deep Learning</em></strong></p>

<p><br />
A Berkeley está disponibilizando publicamente o <a href="https://sites.google.com/view/berkeley-cs294-158-sp20/home">plano de estudos</a> do seu curso em “<em>Deep Unsupervised Learning</em>”, focado principalmente nos aspectos teóricos do <em>self-supervised learning</em> e em modelos generativos. Outros tópicos incluem modelos de variáveis latentes, modelos autorregressivos e <em>flow models</em>. As aulas e os <em>slides</em> também estão disponíveis.</p>

<!-- Berkeley is publicly releasing the [entire syllabus](https://sites.google.com/view/berkeley-cs294-158-sp20/home) for its course on “Deep Unsupervised Learning” mainly focusing on the theoretical aspects of self-supervised learning and generative models. Some topics include latent variable models, autoregressive models, flow models, and self-supervised learning, to name a few. Youtube videos and slides are available. -->

<p><br />
Nós também encontramos essa <a href="https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/">lista impressionante</a> de cursos avançados de ML, NLP e <em>Deep Learning</em> disponível de maneira online.</p>

<!-- We also found this [impressive list](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/) of advanced online courses on machine learning, NLP and deep learning. -->

<p><br />
E aqui está um outro curso intitulado <a href="https://compstat-lmu.github.io/lecture_i2ml/index.html">“Introduction to Machine Learning”</a> que aborda assuntos como regressão supervisionada, avaliação de desempenho, <em>random forests</em>, ajuste de parâmetros, dicas práticas e muito mais.</p>

<!-- And here is another course called [“Introduction to Machine Learning](https://compstat-lmu.github.io/lecture_i2ml/index.html)” which includes topics such as supervised regression, performance evaluation, random forests, parameter tuning, practical advice, and much more. -->

<h1 id="menções-honrosas-️">Menções Honrosas ⭐️</h1>

<p><br />
A edição anterior da Newsletter (6ª edição) está disponível <a href="https://dair.ai/NLP_Newsletter-PT-BR-_BERTology_Primer_fastpages_T5/">aqui</a>.</p>

<!-- The previous NLP Newsletter (Issue #6) is available [here](https://medium.com/dair-ai/nlp-newsletter-bertology-primer-fastpages-t5-data-science-education-pytorch-notebooks-slow-8ae5d499e040). -->

<p><br />
Connon Shorten publicou um <a href="https://www.youtube.com/watch?v=QWu7j1nb_jI&amp;feature=emb_logo">vídeo</a> explicando o modelo ELECTRA, que propõe a utilização de uma técnica chamada <em>replaced token detection</em> como forma de pré-treinar Transformers de maneira mais eficiente. Se você tiver interesse em saber mais, nós também escrevemos um breve resumo do modelo <a href="https://medium.com/dair-ai/nlp-research-highlights-cd522b21b01a">aqui</a>.</p>

<!-- Connon Shorten published a [video](https://www.youtube.com/watch?v=QWu7j1nb_jI&feature=emb_logo) explaining the ELECTRA model which proposes a technique called replaced token detection to pre-train Transformers more efficiently. If you are interested, we also wrote a short summary of the model [here](https://medium.com/dair-ai/nlp-research-highlights-cd522b21b01a). -->

<p><br />
Rachael Tatman está trabalhando numa nova série denominada <a href="https://www.youtube.com/watch?v=-G36q8_cYsc&amp;feature=emb_logo">NLP for Developers</a> onde o objetivo é discutir diferentes métodos de NLP de maneira mais aprofundada, quando utilizá-los e como lidar com dificuldades comuns apresentadas por essas técnicas.</p>

<!-- Rachael Tatman is working on a new series called [NLP for Developers](https://www.youtube.com/watch?v=-G36q8_cYsc&feature=emb_logo) where the idea is to talk more in-depth about different NLP methods, when to use them and explaining common issues that you may run into. -->

<p><br />
A DeepMind liberou o <a href="https://youtu.be/WXuK6gekU1Y">AlphaGo — The Movie</a> no YouTube para celebrar o 4º aniversário da vitória do modelo sobre o Lee Sedol no jogo de Go.</p>

<!-- DeepMind releases [AlphaGo — The Movie](https://youtu.be/WXuK6gekU1Y) on YouTube to celebrate the 4th anniversary of AlphaGo beating Lee Sedol at the game of Go. -->

<p><br />
A OpenMined está com <a href="https://blog.openmined.org/introducing-openmined-research/">vagas abertas</a> para os cargos de <em>Research Engineer e Research Scientist</em>, que parecem ser boas oportunidades para se envolver com <em>privacy-preserving AI</em>.</p>

<!-- OpenMined has [open positions](https://blog.openmined.org/introducing-openmined-research/) for Research Engineer and Research Scientist roles which is a good opportunity to get involved with privacy-preserving AI. -->

<hr />

<p>Se você conhecer bases de dados, projetos, postagens, tutoriais ou artigos que você gostaria de ver na próxima edição da <em>Newsletter</em>, sinta-se a vontade para nos contactar através do e-mail ellfae@gmail.com ou de uma <a href="https://twitter.com/omarsar0">mensagem direta no twitter</a>.</p>

<!-- If you have any datasets, projects, blog posts, tutorials, or papers that you wish to share in the next iteration of the NLP Newsletter, please free to reach out to me at ellfae@gmail.com or ****[**DM on Twitter**](https://twitter.com/omarsar0). -->

<p><br />
<a href="https://dair.ai/newsletter/"><em>Inscreva-se</em></a> <em>🔖 para receber as próximas edições na sua caixa de entrada!</em></p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="VictorGarritano/personal_blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/personal_blog/2020/03/16/NLP_Newsletter-PT-BR-_NLP_7.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/personal_blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/personal_blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/personal_blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/VictorGarritano" title="VictorGarritano"><svg class="svg-icon grey"><use xlink:href="/personal_blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/victorgarritano" title="victorgarritano"><svg class="svg-icon grey"><use xlink:href="/personal_blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/vic_garritano" title="vic_garritano"><svg class="svg-icon grey"><use xlink:href="/personal_blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li><li><a rel="me" href="https://t.me/victorgarritano" title="victorgarritano"><svg class="svg-icon grey"><use xlink:href="/personal_blog/assets/minima-social-icons.svg#telegram"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
